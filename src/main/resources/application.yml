server:
  port: 8080


spring:
  data:
    redis:
      host: 127.0.0.1
      port: 9379
      password: 123456

  servlet:
    multipart:
      max-file-size: 10MB
      max-request-size: 10MB
  application:
    name: openai-chat-bot
  ai:
    openai:
      base-url: https://dashscope.aliyuncs.com/compatible-mode
      api-key: sk-0ff8034547cc4716a2ac8dfd7618e897
      chat:
        options:
          model: qwen-vl-max

          temperature: 0.8

    vectorstore:
      redis:
        initialize-schema: true # 是否初始化所需的模式
        index-name: lee-vectorstore # 用于存储向量的索引名称
        prefix: 'lee:' # redis 键的前缀

llm:
  platform:

    dashscope:
      baseurl: https://dashscope.aliyuncs.com/compatible-mode
      apikey: sk-0ff8034547cc4716a2ac8dfd7618e897
      options:
        model: qwen-omni-turbo-realtime
        temperature: 0.8
        max-tokens: 1024

    modelscope:
      baseurl: https://api-inference.modelscope.cn
      apikey: ms-041e1996-c54f-465e-90d8-6beba54959ae
      options:
        model: Qwen/Qwen3-Next-80B-A3B-Instruct
        temperature: 0.8
        max-tokens: 1024

    iflow:
      baseurl: https://apis.iflow.cn
      apikey: sk-310621af645c12641a3264c50ea9d0e8
      options:
        model: qwen3-vl-plus
        temperature: 0.8
        max-tokens: 1024


logging:
  level:
    org.springframework.ai.chat.client.advisor: DEBUG
    com.example.javaai: DEBUG
#    com.example.javaai.config.CustomAiConfiguration: DEBUG
#    org.springframework.boot.autoconfigure: DEBUG
#    org.springframework.ai.autoconfigure: DEBUG
#    org.springframework.ai: DEBUG
#    org.springframework.context: DEBUG


#阿里云存储桶配置
aliyun :
  oss:
    endpoint: https://oss-cn-beijing.aliyuncs.com
    bucket: java-ai-1968
    region: cn-beijing